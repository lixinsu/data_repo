{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/data/sulixin/research/contest/WikiQACodePackage/data/wiki/WikiQASent-train.txt'\n",
    "dev_file =  '/data/sulixin/research/contest/WikiQACodePackage/data/wiki/WikiQASent-dev.txt'\n",
    "test_file = '/data/sulixin/research/contest/WikiQACodePackage/data/wiki/WikiQASent-test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(data_file):\n",
    "    rv = []\n",
    "    for line in open(data_file):\n",
    "        data = line.strip().split('\\t')\n",
    "        assert len(data) == 3\n",
    "        assert data[-1] in set(['0', '1'])\n",
    "        rv.append({'query': data[0], 'passage': data[1], 'label': data[-1]})\n",
    "    return rv \n",
    "train = load_file(train_file)\n",
    "dev = load_file(dev_file)\n",
    "test = load_file(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========train=======\n",
      "        passage_len     query_len     label_int\n",
      "count  20360.000000  20360.000000  20360.000000\n",
      "mean      25.290766      7.117534      0.051081\n",
      "std       13.019002      2.578649      0.220167\n",
      "min        1.000000      2.000000      0.000000\n",
      "25%       16.000000      5.000000      0.000000\n",
      "50%       23.000000      7.000000      0.000000\n",
      "75%       32.000000      8.000000      0.000000\n",
      "max      236.000000     23.000000      1.000000\n",
      "       passage_len    query_len    label_int\n",
      "count  2118.000000  2118.000000  2118.000000\n",
      "mean     25.300579     7.156280     0.079204\n",
      "std       6.786060     2.570615     0.147173\n",
      "min       2.250000     2.000000     0.000000\n",
      "25%      21.166667     5.000000     0.000000\n",
      "50%      24.785714     7.000000     0.000000\n",
      "75%      28.692308     8.000000     0.111111\n",
      "max     111.000000    23.000000     1.000000\n",
      "       passage_len   query_len   label_int\n",
      "count   873.000000  873.000000  873.000000\n",
      "mean     25.779438    6.454754    0.192158\n",
      "std       7.164447    2.072223    0.175655\n",
      "min       4.666667    3.000000    0.033333\n",
      "25%      21.625000    5.000000    0.076923\n",
      "50%      25.285714    6.000000    0.142857\n",
      "75%      29.125000    7.000000    0.250000\n",
      "max     111.000000   22.000000    1.000000\n",
      "             label      passage  passage_len    query_len    label_int\n",
      "count  2118.000000  2118.000000  2118.000000  2118.000000  2118.000000\n",
      "mean      9.612842     9.612842     9.612842     9.612842     9.612842\n",
      "std       6.232942     6.232942     6.232942     6.232942     6.232942\n",
      "min       1.000000     1.000000     1.000000     1.000000     1.000000\n",
      "25%       5.000000     5.000000     5.000000     5.000000     5.000000\n",
      "50%       8.000000     8.000000     8.000000     8.000000     8.000000\n",
      "75%      13.000000    13.000000    13.000000    13.000000    13.000000\n",
      "max      30.000000    30.000000    30.000000    30.000000    30.000000\n",
      "\n",
      "========dev=======\n",
      "       passage_len    query_len    label_int\n",
      "count  2733.000000  2733.000000  2733.000000\n",
      "mean     24.592755     7.335529     0.051226\n",
      "std      12.829461     2.679932     0.220498\n",
      "min       1.000000     3.000000     0.000000\n",
      "25%      15.000000     5.000000     0.000000\n",
      "50%      23.000000     7.000000     0.000000\n",
      "75%      32.000000     9.000000     0.000000\n",
      "max     132.000000    24.000000     1.000000\n",
      "       passage_len   query_len   label_int\n",
      "count   296.000000  296.000000  296.000000\n",
      "mean     24.644366    7.233108    0.089516\n",
      "std       6.521157    2.892958    0.163502\n",
      "min       7.666667    3.000000    0.000000\n",
      "25%      21.000000    5.000000    0.000000\n",
      "50%      24.861111    7.000000    0.000000\n",
      "75%      28.205556    9.000000    0.125000\n",
      "max      45.750000   24.000000    1.000000\n",
      "       passage_len   query_len   label_int\n",
      "count   126.000000  126.000000  126.000000\n",
      "mean     24.992174    6.563492    0.210292\n",
      "std       6.632156    2.306499    0.193618\n",
      "min       8.600000    3.000000    0.033333\n",
      "25%      21.321970    5.000000    0.083333\n",
      "50%      25.266667    6.000000    0.142857\n",
      "75%      28.136364    8.000000    0.250000\n",
      "max      45.750000   14.000000    1.000000\n",
      "            label     passage  passage_len   query_len   label_int\n",
      "count  296.000000  296.000000   296.000000  296.000000  296.000000\n",
      "mean     9.233108    9.233108     9.233108    9.233108    9.233108\n",
      "std      6.226492    6.226492     6.226492    6.226492    6.226492\n",
      "min      1.000000    1.000000     1.000000    1.000000    1.000000\n",
      "25%      5.000000    5.000000     5.000000    5.000000    5.000000\n",
      "50%      8.000000    8.000000     8.000000    8.000000    8.000000\n",
      "75%     12.000000   12.000000    12.000000   12.000000   12.000000\n",
      "max     30.000000   30.000000    30.000000   30.000000   30.000000\n",
      "\n",
      "========test=======\n",
      "       passage_len    query_len    label_int\n",
      "count   6165.00000  6165.000000  6165.000000\n",
      "mean      24.95296     7.315166     0.047526\n",
      "std       12.65464     2.644973     0.212779\n",
      "min        1.00000     3.000000     0.000000\n",
      "25%       16.00000     6.000000     0.000000\n",
      "50%       23.00000     7.000000     0.000000\n",
      "75%       31.00000     9.000000     0.000000\n",
      "max      112.00000    21.000000     1.000000\n",
      "       passage_len   query_len   label_int\n",
      "count   633.000000  633.000000  633.000000\n",
      "mean     24.953012    7.257504    0.078142\n",
      "std       6.279742    2.526764    0.151883\n",
      "min       4.800000    3.000000    0.000000\n",
      "25%      21.200000    5.000000    0.000000\n",
      "50%      24.900000    7.000000    0.000000\n",
      "75%      28.550000    9.000000    0.100000\n",
      "max      55.000000   21.000000    1.000000\n",
      "       passage_len   query_len   label_int\n",
      "count   243.000000  243.000000  243.000000\n",
      "mean     25.174245    6.444444    0.203555\n",
      "std       5.928052    2.067058    0.186041\n",
      "min       8.090909    3.000000    0.033333\n",
      "25%      21.285714    5.000000    0.076923\n",
      "50%      25.142857    6.000000    0.142857\n",
      "75%      29.100000    7.000000    0.250000\n",
      "max      43.000000   17.000000    1.000000\n",
      "            label     passage  passage_len   query_len   label_int\n",
      "count  633.000000  633.000000   633.000000  633.000000  633.000000\n",
      "mean     9.739336    9.739336     9.739336    9.739336    9.739336\n",
      "std      6.378116    6.378116     6.378116    6.378116    6.378116\n",
      "min      1.000000    1.000000     1.000000    1.000000    1.000000\n",
      "25%      5.000000    5.000000     5.000000    5.000000    5.000000\n",
      "50%      8.000000    8.000000     8.000000    8.000000    8.000000\n",
      "75%     13.000000   13.000000    13.000000   13.000000   13.000000\n",
      "max     30.000000   30.000000    30.000000   30.000000   30.000000\n"
     ]
    }
   ],
   "source": [
    "def analysis_by_pandas(data, label=None):\n",
    "    print('\\n========{}======='.format(label))\n",
    "    df = pd.DataFrame(data)\n",
    "    df['passage_len'] = df['passage'].apply(lambda x:len(x.split()))\n",
    "    df['query_len'] = df['query'].apply(lambda x:len(x.split()))\n",
    "    df['label_int'] = df['label'].apply(lambda x:int(x))\n",
    "    print(df.describe())\n",
    "    gdf = df.groupby(['query']).sum()['label_int'].value_counts(normalize=False,ascending=True)\n",
    "    #print(gdf)\n",
    "    gdf = df.groupby(['query']).mean()\n",
    "    print(gdf.describe())\n",
    "    gdf = df.groupby(['query']).mean()\n",
    "    #print(gdf)\n",
    "    print(gdf[gdf['label_int']!=0].describe())\n",
    "    gdf = df.groupby(['query']).count()\n",
    "    print(gdf.describe())\n",
    "analysis_by_pandas(train, 'train')\n",
    "analysis_by_pandas(dev, 'dev')\n",
    "analysis_by_pandas(test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据汇总\n",
    "\n",
    "| train      |     dev |   test   |\n",
    "| :-------- | --------:| :------: |\n",
    "|1245/2118 (no answer/all query)   |   170/296 |  390/633  |\n",
    "| 20360(passages)    |   2733 |  6165  |\n",
    "| 9.61(passages/query)    |   9.233 |   9.73  |\n",
    "| 25.3(words/passage)    |  24.6 |  24.95  |\n",
    "| 7.1(words/query)    |   7.23 |  7.25  |\n",
    "| 0.192(positive/passages on answerable)    |   0.21 |  0.20  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 展示可回答的问题的passage 和 label\n",
    "df = pd.DataFrame(train + dev +test )\n",
    "df['label_int'] = df['label'].apply(int)\n",
    "sub_an = df.groupby(['query']).sum()\n",
    "sub_an = sub_an[sub_an['label_int']!=0]\n",
    "\n",
    "def format_qp(x):\n",
    "    return x[['passage','label']].to_dict(orient='records')\n",
    "sub_qp = df.groupby(['query']).apply(format_qp).to_frame()\n",
    "\n",
    "merge_df = pd.merge(sub_an, sub_qp, how='inner', left_index=True, right_index=True)\n",
    "dd = merge_df.reset_index().to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存query，传到本地去爬取passages\n",
    "json.dump(merge_df.reset_index()[['query']].to_dict(orient='records'), open('/data/sulixin/research/wikiquery.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n"
     ]
    }
   ],
   "source": [
    "# 保存新格式，传到71，进行BERT匹配\n",
    "an_queries = set([x['query'] for x in dd])\n",
    "print(len(an_queries))\n",
    "\n",
    "def format_dataset(data, out_file, an_queries):\n",
    "    fout = open(out_file, 'w')\n",
    "    for idx, d in enumerate(data):\n",
    "        if d['query'] not in an_queries:\n",
    "            continue\n",
    "        fout.write(json.dumps({'id': '{}'.format(idx),\n",
    "                                   'A': d['query'], 'B': d['passage'], 'label': d['label']}) + '\\n')\n",
    "    \n",
    "format_dataset(train, 'train.jsonl', an_queries)\n",
    "format_dataset(dev, 'dev.jsonl', an_queries)\n",
    "format_dataset(test, 'test.jsonl', an_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir wikiqa_with_sent_1_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save wikiqa_with_sent_1_sep/train.jsonl\n",
      "save wikiqa_with_sent_1_sep/dev.jsonl\n",
      "82.83302583025831\n",
      "79.82300884955752\n",
      "save wikiqa_with_sent_2_sep/train.jsonl\n",
      "save wikiqa_with_sent_2_sep/dev.jsonl\n",
      "126.96171586715867\n",
      "126.63097345132743\n",
      "save wikiqa_with_sent_3_sep/train.jsonl\n",
      "save wikiqa_with_sent_3_sep/dev.jsonl\n",
      "172.3197647601476\n",
      "171.75486725663717\n",
      "save wikiqa_with_sent_4_sep/train.jsonl\n",
      "save wikiqa_with_sent_4_sep/dev.jsonl\n",
      "214.81480627306274\n",
      "216.29469026548674\n",
      "save wikiqa_with_sent_1/train.jsonl\n",
      "save wikiqa_with_sent_1/dev.jsonl\n",
      "81.83302583025831\n",
      "78.82300884955752\n",
      "save wikiqa_with_sent_2/train.jsonl\n",
      "save wikiqa_with_sent_2/dev.jsonl\n",
      "125.96171586715867\n",
      "125.63097345132743\n",
      "save wikiqa_with_sent_3/train.jsonl\n",
      "save wikiqa_with_sent_3/dev.jsonl\n",
      "171.3197647601476\n",
      "170.75486725663717\n",
      "save wikiqa_with_sent_4/train.jsonl\n",
      "save wikiqa_with_sent_4/dev.jsonl\n",
      "213.81480627306274\n",
      "215.29469026548674\n"
     ]
    }
   ],
   "source": [
    "# 保存带检索文本的新格式，传到71，进行BERT匹配\n",
    "q_ps_mapping = {}\n",
    "for line in open('all_wikiqa_aug.json'):\n",
    "    data = json.loads(line)\n",
    "    q_ps_mapping[data['query']] = data['passages']\n",
    "    \n",
    "\n",
    "def format_dataset_with_sent(data, out_file, an_queries, add_sep=True, topn=3):\n",
    "    if not os.path.exists(os.path.dirname(out_file)):\n",
    "        os.makedirs(os.path.dirname(out_file))\n",
    "    fout = open(out_file, 'w')\n",
    "    expand_query_lengths = []\n",
    "    for idx, d in enumerate(data):\n",
    "        if d['query'] not in an_queries:\n",
    "            continue\n",
    "        if d['query'] not in q_ps_mapping:\n",
    "            print('no retrieval result {}'.format(d['query']))\n",
    "        ps = q_ps_mapping[d['query']]\n",
    "        if add_sep:\n",
    "            expand_query = '{} SS {}'.format(d['query'], ' '.join(ps[:topn]))\n",
    "        else:\n",
    "            expand_query = '{} {}'.format(d['query'], ' '.join(ps[:topn]))\n",
    "        expand_query_lengths.append(len(expand_query.split()) + len(d['passage'].split()))\n",
    "        fout.write(json.dumps({'id': '{}'.format(idx),\n",
    "                                   'A': expand_query, 'B': d['passage'], 'label': d['label']}) + '\\n')\n",
    "    print(statistics.mean(expand_query_lengths))\n",
    "    \n",
    "    \n",
    "for add_sep in [True, False]:\n",
    "    for nb_a in  [1, 2, 3, 4]:\n",
    "        print('save {}'.format('wikiqa_with_sent_{}{}/train.jsonl'.format(nb_a, '_sep' if add_sep else '')))\n",
    "        print('save {}'.format('wikiqa_with_sent_{}{}/dev.jsonl'.format(nb_a, '_sep' if add_sep else '')))\n",
    "        format_dataset_with_sent(train, 'wikiqa_with_sent_{}{}/train.jsonl'.format(nb_a, '_sep' if add_sep else ''),\n",
    "                                   an_queries, topn=nb_a, add_sep=add_sep)\n",
    "        format_dataset_with_sent(dev, 'wikiqa_with_sent_{}{}/dev.jsonl'.format(nb_a, '_sep' if add_sep else ''),\n",
    "                                   an_queries, topn=nb_a, add_sep=add_sep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> wikiqa_with_sent_1_sep/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? A A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged.\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? A A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged.\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n",
      "\n",
      "==> wikiqa_with_sent_1/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged.\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged.\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n",
      "==> wikiqa_with_sent_2/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged. Some glacier caves are formed by geothermal heat from volcanic vents or hotsprings beneath the ice. An extreme example is the Kverkfj\\u00f6ll glacier cave in the Vatnaj\\u00f6kull glacier in Iceland , measured in the 1980s at 2.8 kilometres (1.7 mi) long with a vertical range of 525 metres (1,722 ft).\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged. Some glacier caves are formed by geothermal heat from volcanic vents or hotsprings beneath the ice. An extreme example is the Kverkfj\\u00f6ll glacier cave in the Vatnaj\\u00f6kull glacier in Iceland , measured in the 1980s at 2.8 kilometres (1.7 mi) long with a vertical range of 525 metres (1,722 ft).\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n",
      "\n",
      "==> wikiqa_with_sent_1/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged.\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? A glacier cave can also be formed by geothermal heat in the ground below a glacier. Warm air during the summer can enter and increase the size of a glacier cave. Where a glacier meets a body of water, wave action can form a glacier cave that may be partially submerged.\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n2 wikiqa_with_sent_1_sep/train.jsonl wikiqa_with_sent_1/train.jsonl\n",
    "!head -n2 wikiqa_with_sent_2/train.jsonl wikiqa_with_sent_1/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save wikiqa_with_answer_1_sep/train.jsonl\n",
      "save wikiqa_with_answer_1_sep/dev.jsonl\n",
      "no retrieval result what is high emotional intelligence ?\n",
      "39.52709870848709\n",
      "39.11592920353982\n",
      "save wikiqa_with_answer_2_sep/train.jsonl\n",
      "save wikiqa_with_answer_2_sep/dev.jsonl\n",
      "46.424008302583026\n",
      "45.727433628318586\n",
      "save wikiqa_with_answer_3_sep/train.jsonl\n",
      "save wikiqa_with_answer_3_sep/dev.jsonl\n",
      "52.583487084870846\n",
      "51.59557522123894\n",
      "save wikiqa_with_answer_4_sep/train.jsonl\n",
      "save wikiqa_with_answer_4_sep/dev.jsonl\n",
      "59.492273985239855\n",
      "57.59911504424779\n",
      "save wikiqa_with_answer_1/train.jsonl\n",
      "save wikiqa_with_answer_1/dev.jsonl\n",
      "38.52709870848709\n",
      "38.11592920353982\n",
      "save wikiqa_with_answer_2/train.jsonl\n",
      "save wikiqa_with_answer_2/dev.jsonl\n",
      "45.424008302583026\n",
      "44.727433628318586\n",
      "save wikiqa_with_answer_3/train.jsonl\n",
      "save wikiqa_with_answer_3/dev.jsonl\n",
      "51.583487084870846\n",
      "50.59557522123894\n",
      "save wikiqa_with_answer_4/train.jsonl\n",
      "save wikiqa_with_answer_4/dev.jsonl\n",
      "58.492273985239855\n",
      "56.59911504424779\n"
     ]
    }
   ],
   "source": [
    "# 保存带检索文本的新格式，传到71，进行BERT匹配\n",
    "q_answer_mapping = collections.defaultdict(list)\n",
    "data = json.load(open('predictions.json'))\n",
    "for k, v in data.items():\n",
    "    query = k.split('--p')[0]\n",
    "    q_answer_mapping[query].append(v)\n",
    "    \n",
    "\n",
    "def format_dataset_with_answer(data, out_file, an_queries, topn=3, add_sep=True):\n",
    "    if not os.path.exists(os.path.dirname(out_file)):\n",
    "        os.makedirs(os.path.dirname(out_file))\n",
    "    fout = open(out_file, 'w')\n",
    "    expand_query_lengths = []\n",
    "    for idx, d in enumerate(data):\n",
    "        if d['query'] not in an_queries:\n",
    "            continue\n",
    "        if d['query'] not in q_answer_mapping:\n",
    "            print('no retrieval result {}'.format(d['query']))\n",
    "        aug = ' '.join(q_answer_mapping[d['query']][:topn])\n",
    "        if add_sep:\n",
    "            expand_query = '{} AA {}'.format(d['query'], aug)\n",
    "        else:\n",
    "            expand_query = '{} {}'.format(d['query'], aug)\n",
    "        expand_query_lengths.append(len(expand_query.split()) + len(d['passage'].split()))\n",
    "        fout.write(json.dumps({'id': '{}'.format(idx),\n",
    "                                   'A': expand_query, 'B': d['passage'], 'label': d['label']}) + '\\n')\n",
    "    print(statistics.mean(expand_query_lengths))\n",
    "    \n",
    "\n",
    "for add_sep in [True, False]:\n",
    "    for nb_a in  [1, 2, 3, 4]:\n",
    "        print('save {}'.format('wikiqa_with_answer_{}{}/train.jsonl'.format(nb_a, '_sep' if add_sep else '')))\n",
    "        print('save {}'.format('wikiqa_with_answer_{}{}/dev.jsonl'.format(nb_a, '_sep' if add_sep else '')))\n",
    "        format_dataset_with_answer(train, 'wikiqa_with_answer_{}{}/train.jsonl'.format(nb_a, '_sep' if add_sep else ''),\n",
    "                                   an_queries, topn=nb_a, add_sep=add_sep)\n",
    "        format_dataset_with_answer(dev, 'wikiqa_with_answer_{}{}/dev.jsonl'.format(nb_a, '_sep' if add_sep else ''),\n",
    "                                   an_queries, topn=nb_a, add_sep=add_sep)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> wikiqa_with_answer_1_sep/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? A geothermal heat\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? A geothermal heat\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n",
      "\n",
      "==> wikiqa_with_answer_1/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? geothermal heat\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? geothermal heat\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n",
      "==> wikiqa_with_answer_2/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? geothermal heat geothermal heat from volcanic vents or hotsprings beneath the ice\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? geothermal heat geothermal heat from volcanic vents or hotsprings beneath the ice\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n",
      "\n",
      "==> wikiqa_with_answer_1/train.jsonl <==\n",
      "{\"id\": \"0\", \"A\": \"how are glacier caves formed ? geothermal heat\", \"B\": \"A partly submerged glacier cave on Perito Moreno Glacier .\", \"label\": \"0\"}\n",
      "{\"id\": \"1\", \"A\": \"how are glacier caves formed ? geothermal heat\", \"B\": \"The ice facade is approximately 60 m high\", \"label\": \"0\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n2 wikiqa_with_answer_1_sep/train.jsonl wikiqa_with_answer_1/train.jsonl\n",
    "!head -n2 wikiqa_with_answer_2/train.jsonl wikiqa_with_answer_1/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成SQuAD格式\n",
    "rv = {'data':[]}\n",
    "for line in open('all_wikiqa_aug.json'):\n",
    "    data = json.loads(line)\n",
    "    query = data['query']\n",
    "    for pidx, p in enumerate(data['passages']):\n",
    "        rv['data'].append({\"paragraphs\": [{\"context\": p, \"qas\": [{\"id\": '{}--p{}'.format(query, pidx), \"question\": query}]}]})\n",
    "json.dump(rv, open('wikiqa_squad.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sulixin/research/contest/data_repo/wikiqa_squad.json\r\n"
     ]
    }
   ],
   "source": [
    "!realpath wikiqa_squad.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"Where I can buy good oil for massage?\", \"passages\": [\"A solar eclipse occurs when an observer (on Earth) passes through the shadow cast by the Moon which fully or partially blocks (\\\"occults\\\") the Sun.This can only happen when the Sun, Moon and Earth are nearly aligned on a straight line in three dimensions during a new moon when the Moon is close to the ecliptic plane. In a total eclipse, the disk of the Sun is fully obscured by the Moon.\", \"Partial solar eclipses. A partial solar eclipse occurs when only the penumbra (the partial shadow) passes over you. In these cases, a part of the sun always remains in view during the eclipse.\", \"This is NASA's official solar eclipse page. It contains maps and tables for 5,000 years of lunar eclipses and includes information on eclipse photography and observing tips.\", \"The third and final solar eclipse of the year will be a \\\"ring of fire\\\" eclipse on Dec. 26, and it will be visible from Saudi Arabia, Qatar, India, Sumatra, Borneo, Guam and the Philippines.\", \"\\\"A Solar Eclipse is happening!\\\" A Solar Eclipse is a Hardmode event that occurs rarely after at least one Mechanical Boss has been defeated. A Solar Eclipse has a 1/20 (5%) chance of occurring on any particular day.On the Desktop version and Console version, it is also possible to summon a Solar Eclipse using a Solar Tablet (crafted from Solar Tablet Fragments dropped by Lihzahrds and Flying ...\", \"Jul 02, 2019 \\u00b7 Total solar eclipse on Tuesday, July 2, 2019: Where and when is the Sun eclipse visible? Path map, animation, and local times.\", \"Solar Eclipse Meaning. A solar eclipse is just like a regular new moon where the Moon passes between Earth and the Sun. However, a solar eclipse is more powerful because the Moon darkens the Sun. Solar Eclipse July 2019 is a total solar eclipse so none of the Sun will be visible.\", \"A total solar eclipse is unlike anything you've seen in your life. As totality approaches, you will see the astonishing sight of day turning to night and the Sun's corona blazing in the sky. This is truly a great American eclipse because totality will sweep the nation from the Pacific to the Atlantic.\", \"Serious eclipse chasers are now planning for the succeeding total solar eclipses in South America on July 2, 2019, again in South America on December 14, 2020, and in Antarctica on December 4, 2021. For those hardcore eclipse chasers, here is your vacation guide for a lifetime.\", \"Jul 02, 2019 \\u00b7 What Does the Map Show? The map shows the visibility of the total solar eclipse on July 2, 2019.You can select any location to see the local type, date, and time of the eclipse. Animation showing this eclipse in your city.\"]}\r\n",
      "{\"query\": \"Dear Members; I have my wife in qatar on family visit visa; now it's gonna over 6 months; can i get more 2/3 months visa?? what is the procedure?? pls inform.\", \"passages\": [\"Mar 21, 2019 \\u00b7 Family Residence Visa. Expats are allowed to sponsor their immediate family members. Every family member, including infants, should possess an individual Family Residence Visa to live in Qatar. The visa can be purchased for a period of one to five years and will be stamped in the passport of the family member.\", \"UAE Family Residence Visa new rules. Here is what you should do \\u2013 2016 update. DTAC 2016 for Toastmasters \\u2013 Abu Dhabi, UAE 24-26 May February 14, 2016. New UAE Traffic Rules and Fines 2017 by UAE Ministry \\u2013 Take precautions\", \"Apr 18, 2017 \\u00b7 My wife and kids stay with me. My kids attend school here in my home town and my wife is a homemaker. i just want to visit with my family to usa for 2-3 weeks max(i can get only this much leave). 1: I have 2 fully paid apartments in my name and 1 more under a payment plan for 2 more years. All of them yield good rental income.\", \"Family Reunion \\u2013 Pakistan \\u2013 General info for all to avoid mistakes ... to me from islamabad embassy and verified all documents and last month i visited karachi consulate and applied for family reunion visa my wife is there and she is EU member its been 5 weeks i have applied and how long does it take and i will have to go again for ...\", \"Mar 04, 2014 \\u00b7 Schengen visa for spouses / family members of EU nationals In a previous post, I had mentioned how it was pretty hard to get a schengen visa to travel to Portugal in 2011. The issues were compounded by the fact that I had recently quit my job in Dubai to travel the world and as such, an un-employed [self employed ;)] single Indian male ...\", \"May 01, 2019 \\u00b7 However, my question is more around does it matter how long my H-1B visa should be valid (like atleast 6 months) while I travel to DR ? Based on my H-1B visa expiration date and travel date, I will have a little over 5 months of my H-1B visa valid during my travel. Please advise. Thanks again for all the useful information !\"]}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n2 semeval_query_aug.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
